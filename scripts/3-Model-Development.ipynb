{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f6f7be3",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ariesslin/ie7500-g1-tweet-sentiment-nlp/blob/main/scripts/3.%20Model_Development.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d67c03-2ae7-41f6-81d0-56fe632ece80",
   "metadata": {
    "id": "10d67c03-2ae7-41f6-81d0-56fe632ece80"
   },
   "source": [
    "<div style=\"background-color:#e6f2ff; border-left:8px solid #0059b3; padding:20px; margin:20px 0;\">\n",
    "  <h2 style=\"color:#003366;\"><strong>3. Model Development</strong></h2>\n",
    "  <p style=\"color:#333333;\">Model Selection and Preliminary Performance Testing</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bOElrufQWr4t",
   "metadata": {
    "id": "bOElrufQWr4t"
   },
   "source": [
    "## Model Development Overview: Multi-Architecture Sentiment Classification\n",
    "\n",
    "This notebook presents a structured comparison of three complementary approaches to tweet sentiment classification: **TF-IDF + Logistic Regression**, **Bidirectional LSTM**, and **DistilBERT**. Each model represents a different point on the spectrum from traditional machine learning to state-of-the-art deep learning.\n",
    "\n",
    "### Three-Model Comparison Strategy\n",
    "\n",
    "Our multi-model approach systematically evaluates:\n",
    "\n",
    "1. **Classical Baseline**: TF-IDF + Logistic Regression for interpretable, fast classification\n",
    "2. **Deep Learning**: Bidirectional LSTM for context-aware sequential modeling  \n",
    "3. **Transformer**: DistilBERT for sophisticated contextual understanding\n",
    "\n",
    "### Evaluation Methodology\n",
    "\n",
    "All models are evaluated using consistent metrics including accuracy, precision, recall, F1-score, and computational efficiency to enable fair comparison and informed model selection.\n",
    "\n",
    "### Notebook Structure\n",
    "\n",
    "This notebook provides high-level overviews of each approach, with detailed implementations available in separate focused notebooks:\n",
    "- **Section 3.1**: Baseline model overview\n",
    "- **Section 3.2**: LSTM model overview  \n",
    "- **Section 3.3**: Transformer model overview\n",
    "- **Section 3.4**: Comparative analysis and results\n",
    "\n",
    "The shared data loading and preprocessing below establishes a common foundation for all model comparisons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad9fdb6-b723-469c-a345-f2bbed6055a6",
   "metadata": {
    "id": "5ad9fdb6-b723-469c-a345-f2bbed6055a6"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82172ce7-5869-4448-8c89-3e9450c1e426",
   "metadata": {
    "id": "82172ce7-5869-4448-8c89-3e9450c1e426"
   },
   "source": [
    "\n",
    "<div style=\"background-color:#e6f2ff; border-left:8px solid #0059b3; padding:20px; margin:20px 0;\">\n",
    "  <h2 style=\"color:#003366;\"><strong>3.1 Baseline Model â€“ TF-IDF + Logistic Regression</strong></h2>\n",
    "  <p style=\"color:#333333;\">Overview of TF-IDF vectorization + logistic regression baseline model.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defa0c91-f0d1-44a5-82c5-789b0bd1e5e7",
   "metadata": {
    "id": "07efb030-35ad-4e70-9186-b72e6bd676ec"
   },
   "source": [
    "## Baseline Model Overview: TF-IDF + Logistic Regression\n",
    "\n",
    "The **TF-IDF + Logistic Regression** model serves as our baseline for tweet sentiment classification. This approach combines term frequency-inverse document frequency vectorization with a linear classifier to provide a strong, interpretable foundation for comparison.\n",
    "\n",
    "### Key Features of the Baseline Model:\n",
    "\n",
    "**TF-IDF Vectorization:**\n",
    "- Converts raw tweets into numerical feature vectors\n",
    "- Measures word importance relative to the entire corpus\n",
    "- Handles sparse, high-dimensional text data effectively\n",
    "- Applies L2 normalization to prevent length bias\n",
    "\n",
    "**Logistic Regression Classifier:**\n",
    "- Linear model that's fast to train and highly interpretable  \n",
    "- Provides probability estimates for sentiment predictions\n",
    "- Works well with TF-IDF's sparse feature representation\n",
    "- Enables coefficient analysis to understand word influences\n",
    "\n",
    "**Hyperparameter Optimization:**\n",
    "- Grid search across TF-IDF parameters (max_features, ngram_range, min_df, max_df)\n",
    "- Logistic regression tuning (regularization strength, class weighting)\n",
    "- 3-fold cross-validation for robust parameter selection\n",
    "- Weighted F1-score optimization for balanced performance\n",
    "\n",
    "### Performance Summary:\n",
    "- **Validation Accuracy**: ~79-78%\n",
    "- **F1 Score**: ~83-79%\n",
    "- **Strengths**: Fast, interpretable, solid baseline performance\n",
    "- **Limitations**: Context-insensitive, struggles with negation and nuance\n",
    "\n",
    "### For Detailed Implementation:\n",
    "ðŸ““ **See complete implementation, hyperparameter tuning, error analysis, and interpretability insights in [`3a-Logistic-Regression.ipynb`](./3a-Logistic-Regression.ipynb)**\n",
    "\n",
    "The detailed notebook includes:\n",
    "- Comprehensive data preprocessing and tokenization\n",
    "- GridSearchCV hyperparameter optimization with 96 parameter combinations\n",
    "- Model coefficient analysis and word importance visualization\n",
    "- Extensive error analysis on misclassified tweets\n",
    "- Discussion of model strengths and limitations\n",
    "\n",
    "This baseline establishes the performance threshold that our deep learning models (LSTM and BERT) should surpass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b2c984-64e4-49a4-afab-160dfbc2a57a",
   "metadata": {
    "id": "61b2c984-64e4-49a4-afab-160dfbc2a57a"
   },
   "source": [
    "\n",
    "<div style=\"background-color:#e6f2ff; border-left:8px solid #0059b3; padding:20px; margin:20px 0;\">\n",
    "  <h2 style=\"color:#003366;\"><strong>3.2 Deep Learning Model â€“ Bidirectional LSTM</strong></h2>\n",
    "  <p style=\"color:#333333;\">Bidirectional LSTM with Word2Vec embeddings for sequence-aware sentiment analysis.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825d603b-9b00-41df-940e-30e8ad80c8b6",
   "metadata": {
    "id": "to08L5gzucYG"
   },
   "source": [
    "## Deep Learning Sentiment Classifier: Bidirectional LSTM with Word2Vec Embeddings\n",
    "\n",
    "The **Bidirectional LSTM + Word2Vec** model represents our deep learning approach for tweet sentiment classification, designed to capture the sequential nature of language and semantic relationships between words.\n",
    "\n",
    "### Key Features of the LSTM Model:\n",
    "\n",
    "**Word2Vec Embeddings:**\n",
    "- Dense word vectors that capture semantic relationships between words\n",
    "- Trained specifically on our tweet corpus for domain-specific representations  \n",
    "- 100-dimensional embeddings with 100% vocabulary coverage\n",
    "- Words with similar meanings positioned close together in embedding space\n",
    "\n",
    "**Bidirectional LSTM Architecture:**\n",
    "- Processes text in both forward and backward directions for complete context understanding\n",
    "- Two-layer bidirectional LSTM with 128 and 64 hidden units respectively\n",
    "- Dropout layers (0.5 and 0.3) to prevent overfitting during training\n",
    "- Captures long-term dependencies and sequential patterns in tweets\n",
    "\n",
    "**Advanced Features:**\n",
    "- Handles negation, word order, and contextual sentiment better than baseline\n",
    "- Early stopping with patience=3 to prevent overfitting\n",
    "- Nadam optimizer for improved convergence on noisy tweet data\n",
    "- Sequence padding to handle variable tweet lengths efficiently\n",
    "\n",
    "### Performance Summary:\n",
    "- **Validation Accuracy**: ~80.14%\n",
    "- **F1 Score**: ~80.15%\n",
    "- **Strengths**: Context-aware, handles sequence patterns, semantic understanding\n",
    "- **Limitations**: Computationally expensive, requires more training time\n",
    "\n",
    "### For Detailed Implementation:\n",
    "ðŸ““ **See complete implementation, Word2Vec training, architecture details, and comprehensive error analysis in [`3b-LSTM.ipynb`](./3b-LSTM.ipynb)**\n",
    "\n",
    "The detailed notebook includes:\n",
    "- Custom Word2Vec training on the tweet corpus with 90K+ vocabulary\n",
    "- Bidirectional LSTM architecture with embedding matrix construction\n",
    "- Comprehensive error analysis with specific examples from model output\n",
    "- Evidence-based insights into model strengths and limitations\n",
    "- Performance comparison with baseline model\n",
    "\n",
    "This LSTM model bridges the gap between simple linear models and sophisticated transformers, providing strong performance with interpretable sequential modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164b2d45-8f4b-40cb-8728-2a50a2b8f18b",
   "metadata": {
    "id": "164b2d45-8f4b-40cb-8728-2a50a2b8f18b"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabdf2dd-b6d2-4007-923c-f7825eba8057",
   "metadata": {
    "id": "aabdf2dd-b6d2-4007-923c-f7825eba8057"
   },
   "source": [
    "\n",
    "<div style=\"background-color:#e6f2ff; border-left:8px solid #0059b3; padding:20px; margin:20px 0;\">\n",
    "  <h2 style=\"color:#003366;\"><strong>3.3 Transformer Model â€“ DistilBERT</strong></h2>\n",
    "  <p style=\"color:#333333;\">Fine-tuning DistilBERT for state-of-the-art contextual sentiment analysis.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480b3fc6-5245-4190-b687-99612f572e5c",
   "metadata": {
    "id": "f6c94bb9-609c-486b-8f8b-65b4639e6aa1"
   },
   "source": [
    "## Transformer: DistilBERT Fine-tuning\n",
    "\n",
    "The **DistilBERT** model represents our state-of-the-art approach for tweet sentiment classification, leveraging pre-trained transformer architecture for deep contextual understanding.\n",
    "\n",
    "### Key Features of the DistilBERT Model:\n",
    "\n",
    "**Pre-trained Transformer Architecture:**\n",
    "- Distilled version of BERT with 97% of BERT's performance using 60% fewer parameters\n",
    "- Pre-trained on 16GB of text data, providing rich contextual representations\n",
    "- Bidirectional attention mechanism for complete sentence understanding\n",
    "- Fine-tuned specifically for binary sentiment classification\n",
    "\n",
    "**Advanced NLP Capabilities:**\n",
    "- Handles complex linguistic patterns like sarcasm, negation, and context-dependent sentiment\n",
    "- Understands word relationships across entire tweet sequences simultaneously\n",
    "- Processes subword tokens for better handling of informal social media language\n",
    "- Maximum sequence length of 140 tokens optimized for tweet analysis\n",
    "\n",
    "**Training Configuration:**\n",
    "- 2 epochs with learning rate of 1e-4 for effective fine-tuning\n",
    "- Batch size of 32 for efficient GPU utilization\n",
    "- Early stopping and weight decay for regularization\n",
    "- Specialized tokenizer for handling Twitter-specific language patterns\n",
    "\n",
    "### Performance Summary:\n",
    "- **Validation Accuracy**: ~81.49%\n",
    "- **Precision**: ~83.18% (highest among all models)\n",
    "- **Recall**: ~86.54%\n",
    "- **F1 Score**: ~84.83%\n",
    "- **Strengths**: Superior contextual understanding, handles complex linguistic patterns\n",
    "- **Limitations**: Computationally expensive, requires significant GPU resources\n",
    "\n",
    "### For Detailed Implementation:\n",
    "ðŸ““ **See complete implementation, fine-tuning process, optimization techniques, and comprehensive performance analysis in [`3c-BERT.ipynb`](./3c-BERT.ipynb)**\n",
    "\n",
    "The detailed notebook includes:\n",
    "- Comprehensive DistilBERT tokenization and dataset preparation\n",
    "- Complete fine-tuning implementation with Hugging Face Transformers\n",
    "- Advanced optimization techniques (mixed precision training, optimized sequence length)\n",
    "- Extensive performance analysis and error evaluation\n",
    "- Comparison with baseline and LSTM models\n",
    "\n",
    "This transformer model achieves the highest precision among all approaches, making it ideal for applications where accurate positive sentiment detection is critical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e3b1cc-bf9a-4b07-9111-0bfadff815c7",
   "metadata": {
    "id": "21827938-c09d-4fc9-ab90-118c407f2b75"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a4741c-4ee7-4cdc-896c-1cde34dd2576",
   "metadata": {
    "id": "a8a4741c-4ee7-4cdc-896c-1cde34dd2576"
   },
   "source": [
    "\n",
    "<div style=\"background-color:#e6f2ff; border-left:8px solid #0059b3; padding:20px; margin:20px 0;\">\n",
    "  <h2 style=\"color:#003366;\"><strong>3.4 Model Comparison and Results Analysis </strong></h2>\n",
    "  <p style=\"color:#333333;\"></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FOTd56MrOLlh",
   "metadata": {
    "id": "FOTd56MrOLlh"
   },
   "source": [
    "## Model Validation Results and Comparative Analysis for Tweet Sentiment Classification\n",
    "\n",
    "This section presents a detailed evaluation of three models **Logistic Regression**, **LSTM**, and **BERT** trained to classify tweet sentiments as **Negative** or **Positive**. Evaluation is based on confusion matrices, performance metrics, training dynamics, and comparative strengths and weaknesses in the context of tweet sentiment analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Logistic Regression â€” Validation Results\n",
    "\n",
    "**Performance Metrics:**\n",
    "- **Accuracy**: 79.22%\n",
    "- **Precision**: 80.04%\n",
    "- **Recall**: 86.93%\n",
    "- **F1 Score**: 83.34%\n",
    "\n",
    "**Confusion Matrix:**\n",
    "\n",
    "|                   | **Predicted Negative** | **Predicted Positive** |\n",
    "|-------------------|------------------------|-------------------------|\n",
    "| **Actual Negative** | 54,639                 | 26,013                  |\n",
    "| **Actual Positive** | 15,678                 | 100,000+                |\n",
    "\n",
    "**Sentiment Analysis Insights:**\n",
    "- Logistic Regression shows solid baseline performance and favors **recall**, which means it's highly sensitive to detecting **positive sentiments** in tweets.\n",
    "- However, the high number of **false positives (26,013)** suggests it struggles to distinguish **genuinely negative tweets**, often misclassifying them as positive.\n",
    "- This behavior may be due to:\n",
    "  - Over-simplification of tweet content and lack of contextual understanding.\n",
    "  - Tweets containing mixed signals (e.g., sarcasm or slang) being interpreted incorrectly.\n",
    "\n",
    "- **Use Case Suitability**:\n",
    "  - Adequate for large-scale monitoring where missing positive sentiment is riskier than mistakenly flagging negative ones (e.g., brand loyalty tracking).\n",
    "  - Not ideal where negative sentiment needs precise monitoring (e.g., social crisis detection).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. LSTM â€” Validation and Training Results\n",
    "\n",
    "**Performance Metrics:**\n",
    "- **Accuracy**: 81.17%\n",
    "- **Precision**: 81.51%\n",
    "- **Recall**: 88.60%\n",
    "- **F1 Score**: 84.91%\n",
    "\n",
    "**Confusion Matrix:**\n",
    "\n",
    "|                   | **Predicted Negative** | **Predicted Positive** |\n",
    "|-------------------|------------------------|-------------------------|\n",
    "| **Actual Negative** | 56,546                 | 24,106                  |\n",
    "| **Actual Positive** | 13,672                 | 106,290                 |\n",
    "\n",
    "**Training Summary:**\n",
    "- Validation accuracy and loss stabilized around epoch 6, suggesting thatâ€™s the best point to stop training.\n",
    "- Model learned rapidly early on, but overfitting started appearing after epoch 6.\n",
    "\n",
    "**Sentiment Analysis Insights:**\n",
    "- The LSTM model is especially well-suited for sentiment classification on tweets due to its ability to model **sequence dependencies**.\n",
    "- Tweets often contain **non-standard grammar**, **emojis**, and **elongations** (e.g., \"soooo goood\"), which LSTM handles more effectively than a linear model.\n",
    "- Strong performance in **both recall and precision** implies it can:\n",
    "  - Accurately detect **positive** sentiments.\n",
    "  - Avoid incorrectly labeling **negative tweets** as positive.\n",
    "\n",
    "- **Use Case Suitability**:\n",
    "  - Ideal for real-time sentiment dashboards and public opinion tracking tools.\n",
    "  - Offers a strong balance between catching enthusiastic sentiment and minimizing false optimism.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. BERT â€” Validation and Training Results\n",
    "\n",
    "**Performance Metrics:**\n",
    "- **Accuracy**: 81.49%\n",
    "- **Precision**: 83.18%\n",
    "- **Recall**: 86.54%\n",
    "- **F1 Score**: 84.83%\n",
    "\n",
    "**Confusion Matrix:**\n",
    "\n",
    "|                   | **Predicted Negative** | **Predicted Positive** |\n",
    "|-------------------|------------------------|-------------------------|\n",
    "| **Actual Negative** | ~60,000                | 20,991                  |\n",
    "| **Actual Positive** | 16,150                 | 100,000+                |\n",
    "\n",
    "**Training Summary:**\n",
    "- Training loss dropped smoothly from 0.4557 â†’ 0.3960 over 55,000 steps.\n",
    "- Stable and consistent learning curve, reflecting effective pretraining and fine-tuning.\n",
    "\n",
    "**Sentiment Analysis Insights:**\n",
    "- BERT outperforms all models in **precision**, meaning it is highly accurate in identifying **positive sentiment** when it makes that prediction.\n",
    "- This is crucial for tweets where subtle context (e.g., sarcasm, negation, idioms) makes sentiment ambiguous.\n",
    "- The slightly lower recall (compared to LSTM) indicates BERT may miss some **less explicit** positive tweets, possibly those that use slang or non-standard formatting unseen during fine-tuning.\n",
    "\n",
    "- **Use Case Suitability**:\n",
    "  - Excellent for **automated sentiment scoring**, content moderation, or **flagging key influencer reactions**.\n",
    "  - Especially beneficial when **false positives** (mistakenly labeling negativity as positivity) are more damaging (e.g., in reputation management or crisis alerts).\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Comparative Model Analysis and Recommendations\n",
    "\n",
    "| **Metric**          | **Logistic Regression** | **LSTM**           | **BERT**           |\n",
    "|---------------------|--------------------------|--------------------|--------------------|\n",
    "| Accuracy            | 79.22%                   | 81.17%             | **81.49%**         |\n",
    "| Precision (Positive)| 80.04%                   | 81.51%             | **83.18%**         |\n",
    "| Recall (Positive)   | 86.93%                   | **88.60%**         | 86.54%             |\n",
    "| F1 Score            | 83.34%                   | **84.91%**         | 84.83%             |\n",
    "| False Positives     | 26,013                   | 24,106             | **20,991**         |\n",
    "| False Negatives     | 15,678                   | **13,672**         | 16,150             |\n",
    "\n",
    "**Overall Insights:**\n",
    "- **Logistic Regression** remains a decent choice for high-volume, low-compute environments, where identifying most of the **positive sentiments** is more critical than precision.\n",
    "- **LSTM** is the most **balanced** model, particularly effective at picking up **positive sentiment** while minimizing false detections. Its sequential modeling helps handle emotive expressions common in tweets.\n",
    "- **BERT** offers the best **precision**, indicating itâ€™s the most confident and contextually aware when assigning **positive sentiment**, but it may miss tweets that use creative or ambiguous language."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
